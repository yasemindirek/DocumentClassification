 A system that searches a database of billions of facial images could help Ukraine uncover Russian infiltrators, fight misinformation and identify the dead, a company has said. Facial recognition firm Clearview AI has offered its services to Ukraine's government. The company says it has a searchable database of 10 billion faces sourced from the web. But the technology has previously attracted fines from data regulators. "I'm pleased to confirm that Clearview AI has provided its groundbreaking facial recognition technology to Ukrainian officials for their use during the crisis they are facing," chief executive Hoan Ton-That told the BBC in a statement.  Clearview AI offered its services for free in a letter to Ukraine's government, first reported by Reuters, which the BBC has seen.  It says that a large portion of its database of faces is drawn is from Russian social media sites.  The letter claims that the company has more than two billion images from the Vkontakte (VK), a social network sometimes dubbed the "Facebook of Russia". The breadth of its Russian coverage makes it more comprehensive than a publicly available rival technology PimEyes, which has previously been used to identify people in war photos, a Clearview AI adviser said. In the letter, Mr Ton-That identifies a number of potential scenarios in which the technology could be useful including: Mr Ton-That said that Ukraine began using the technology on Saturday.   The country's defence ministry has not yet responded to a BBC request for comment. Clearview AI's technology has been criticised by privacy watchdogs. In November the UK's data privacy regulator, the Information Commissioners Office (ICO) issued the company with a provisional £17m fine. It was also fined 20m euros (£16.8m) by Italian regulators recently, after finding it applied "what amounted to biometric monitoring techniques" to individuals in the country. And while its technology is used by US law enforcement, the company is facing lawsuits in America over its use of images gathered from the internet. At least one critic said there was a risk facial recognition could misidentify people at checkpoints.  Albert Fox Cahn, executive director of the Surveillance Technology Oversight Project in New York, told Reuters it was possible "we're going to see well-intentioned technology backfiring and harming the very people it's supposed to help". Mr Ton-That added that Clearview AI should never be used as the sole source of identification.

